\label{GT:chapter}


We have so far assumed that the event organizer knows of or can query preferences and constraints of agents, but in some settings this may not be a realistic assumption. For instance, if agents are strategic, the organizer can no longer assume that agents will report their preferences and constraints truthfull because lying may lead to a better outcome than telling the truth would.


% To understand why strategic behavior of agents can be troublesome, let us consider a small example that features two agents in the Stable Invitations Problem.
%
% \begin{example} \label{GT:eg:strategicAgents}
% 		Consider two agents with identical preferences on the number of participants with no friends or enemies.
% 	\begin{equation*}
% 		\begin{aligned}
% 				S_1 = \{1\}, ~~& S_2 = \{1\}
% 		\end{aligned}
% 	\end{equation*}
%
% Note that both agents have decreasing preferences in this example.
% There are two stable invitations, namely $I_1 \{a_1\}$ and $I_2 = \{a_2\}$.
% The empty invitation ($\emptyset$) is not stable while the full invitation ($\{a_1,a_2\}$) is not individually rational.
%
% If the organizer were to choose $I_1$ given preferences of agents, then $a_2$ would have an incentive to lie -- if $a_2$ had reported her preference as $\hat{S}_2 \{1, 2\}$ instead of $S_2$, then $I_2$ would have been the only stable invitation given $(S_1, \hat{S}_2)$. Clearly, $a_2$ prefers $I_2$ over $I_1$, and therefore $a_2$'s best action in hindsight would have been lying about her preference. By symmetric, the same holds for $a_1$, if the organizer were to choose $I_2$ given $(S_1, S_2)$.
% \end{example}
%
In this chapter we investigate how strategic behavior of agents can complicatethe problem of finding a stable solution in the Stable Invitations Problem and the Group Activity Selection Problem. We begin by considering the least complex problem, which is the intersection of these two problems -- agents have anonymous preferences (i.e., no friends and enemies) and there is only one activity. This is a fairly restrictive assumption, but it reveals interesting interactions between strategic behavior of agents and the objectives in these problems. In fact, as we shall see, it is in general impossible to design a mechanism under which truth-telling is a dominant strategy. In a more restrictive setting, however, where all agents have increasing preferences (i.e., all agents prefer more participants than fewer), we can design a mechanism under which truth-telling is a dominant strategy in addition to many other desirable properties.



\section{Definitions and Notation} \label{GT:sec:prelim}

In this chapter, we study the Anonymous Ordinal Invitations Problem (\AOIP) which is motivated by the Stable Invitations Problem. The term ``anonymous'' emphasizes that agents only care about size of invitations and ``ordinal'' emphasizes that agents do have ordinal prefernces over sizes rather than dichotomic prefernces. 

% Recall from Definition~\ref{SIP:def:instance} that an instance of the Stable Invitations Problem is given by a set of agents $N = \{a_1, a_2, \dots, a_n\}$, a set of friends $F_i$, a set of enemies $R_i$, and an approval set $S_i$ for each agent $a_i$.
%
% We first focus on the special case of this problem when all friend sets and enemy sets are empty sets -- we call this the Anonymous Stable Invitations Problem (\AOIP), which is known to be solvable in polynomial time; this problem is also equivalent to the special case of the Group Activity Selection Problem with just one activity. We then discuss how our technical results extend to the Stable Invitations Problem and the Group Activity Selection Problem.


\begin{definition}
An instance of the Anonymous Ordinal Invitations Problem (\AOIP) is given by a set of agents $N = \{a_1, a_2, \dots, a_n\}$ and a preference $P_i$ for each agent $a_i\in N$. $P_i$ is defined as a total preorder ($\succeq_i$) on the set of outcomes, $x = \{0, 1, 2, \dots, n\}$. An outcome $x\in (X\setminus\{0\})$ denotes the number of attendees and $x = 0$ is a special outcome of not attending. 
For any $x_1, x_2\in (X \setminus\{0\})$, $x_1 \succeq_i x_2$ is interpreted as agent $a_i$ weakly preferring attending the event if $x_1$ attendees are present (including herself) to attending if $x_2$ attendees are present (including herself).
We use $\succ_i$ and $\sim_i$ to denote the induced strict preferences and indifference relations, respectively. 
We drop the subscript ($i$) if it is clear from the context.
\end{definition}

We assume that for each $a_i$ and each $x\in (X\setminus\{0\})$, either $x \succ_i 0$ or $0 \succ_i x$. That is, no agent is indifferent between not attending and any other outcome. This assumption is made for convenience and does not change our technical results.

Let us define three solution concepts of \AOIP.

\begin{definition} \label{GT:def:invitation}
Given an instance of \AOIP, an \emph{invitation} $I$ is a subset of $N$, and is interpreted as the organizer inviting the agents in $I$. 

An invitation $I$ is said to be \emph{individually rational} (IR) if for every agent $a_i\in I$ it holds that $|I| \succ_i 0$. 

An invitation $I$ is said to be \emph{(Nash) stable}ÃŸ if for every agent $a_j\not\in I$ it holds that $|S \cup \{a_j\}| = (|I| + 1) \prec_j 0$ and $I$ is individually rational as well.

An invitation $I$ is said to be \emph{envy-free} if for every agent $a_j\not\in I$ it holds that $|I| \prec_j 0$ and $I$ is individually rational as well.
\end{definition}

In addition to individual rationality, stability states that an agent who is not invited should not wish to participate (even without permission of others), while envy-freeness states that an agent who is not invited should not be envy of someone who's invited. It is worth noting that these two concepts are not equivalent.

For each agent $a_i$, we can naturally induce from $P_i$ her preference over the set of all invitations.
Given $I$ and $I'$, if both contain $a_i$, then the preference relation between $I$ and $I'$ is induced from $P_i$ on $|I|$ and $|I'|$ (their cardinality). If neither contains $a_i$, then both invitations are equivalent to $0$ (the outside option). If $I$ contains $a_i$ and $I'$ does not, then the preference relation is induced from $P_i$ on $|I|$ and $0$. 
We overload our notation ($\sim_i, \succeq_i, \succ_i$) for the induced preferences over invitations. 
The preferences of agents over invitations are now well-defined.

Let us define two special classes of preferences of agents, increasing (\INC) and decreasing (\DEC). Informally, agents with \INC-preferences (\DEC, respectively) prefer the event with more attendees (fewer, respectively). In particular \INC-preference implies that $n$ is the most favorable outcome and \DEC-preference that $1$ is the most favorable outcome.
\begin{definition}\label{GT:def:preferenceTypes}
Agent $a_i$ has an \INC-preference if there is some threshold $l_i$ such that 
$n \succeq_i (n-1) \succeq_i \cdots \succeq_i (l_i) \succ_i 0 \sim k$ for all $1 \leq k < l_i$. 
Agent $a_i$ has a \DEC-preference if there is some threshold $h_i$ such that 
$1 \succeq_i 2 \succeq_i \cdots \succeq_i (h_i) \succ_i 0 \sim k$ for all $h_i < k \leq n$. 
\end{definition}
We assume that agents can have arbitrary preferences, but these two special types preferences play an important role in the strategic case in Section~\ref{GT:sec:Mechanism}. 


Let us consider two small examples of \AOIP.

\begin{example}[Stable invitations are not unique] \label{GT:eg:multiple_stable}
	Let us consider two agents with identical preferences: 
	\begin{equation*}
		\begin{aligned}
				P_1: 1 \succ 0 \succ 2,~~~& P_2: 1 \succ 0 \succ 2
		\end{aligned}
	\end{equation*}
	Note that both agents have \DEC-preferences (with $h_1 = h_2 = 1$).
	The two stable invitations are $I_1 = \{a_1\}$ and $I_2 = \{a_2\}$. 
	The empty invitation ($\emptyset$) exhibits ER while the full invitation ($N$) is not IR. 
\end{example}

\begin{example}[A stable invitation may not exist] \label{GT:eg:noStableSet}
	Let us consider three agents with the following preferences: 
	\begin{equation*}
		\small
		\begin{aligned}
				P_1: 3\succ 2 \succ 0 \succ 1,~ P_2: 1 \succ 0 \succ 2 \sim 3, ~ P_3: 0 \succ 1 \sim 2 \sim 3
		\end{aligned}
	\end{equation*}
	Note that $a_1$ has an \INC-preference (with $l_1 = 2$) while $a_2$ has a \DEC-preference (with  $h_2 = 1$). $a_3$ is simply unwilling to attend the event (no outcome is acceptable to her).
	Due to $a_3$, any invitation including $a_3$ is not IR. Between $a_1$ and $a_2$ only, the empty invitation exhibits ER due to $a_2$, $S_1 = \{a_1\}$ is not IR due to $a_1$, $S_2 = \{a_2\}$ exhibits ER due to $a_1$, and $\{a_1, a_2\}$ is not IR due to $a_2$.
\end{example}









Let us formally define a deterministic mechanism in the context of \AOIPs with strategic agents, and define what constitutes a strategy-proof mechanism. We later discuss in Sectino~\ref{GT:sec:randomized} why our technical results do not change when we consider randomized mechanisms.

\begin{definition} \label{GT:def:mechanism}
Given an instance of \AOIP, we define $V_i$ (the set of available actions to $a_i$) to be the set of all subsets of the set of outcomes, $[1, n]$.\footnote{In the Anonymous Stable Invitations Problem, agents only care about the size of an invitation, not participants.} 
A (deterministic) \emph{mechanism} $\mathcal{M}$ is a pair $(V, Z)$ where $V = (V_1 \times \cdots \times V_n)$ is the set of action profiles of all agents (i.e., $V_i \subset [1,n]$) and $Z: V \mapsto U$ is a mapping from each action profile to an invitation in $U$ where $U = 2^{N}$. 
Let $V_{-i} = (V_1 \times \cdots \times V_{i-1} \times V_{i+1} \times \cdots \times V_{n})$ be the set of action profiles available to all agents but agent $a_i$. A mechanism $\mathcal{M} = (V, Z)$ is said to be \emph{strategy-proof} if for all $a_i\in N$, $a_i$ prefers the invitation $Z(S_i, v_{-i})$ over the invitation $Z(v_i, v_{-i})$ for all $v_i \in V_i$ and $v_{-i} \in V_{-i}$.
\end{definition}

In words, mechanism $\mathcal{M}$ is strtaegy-proof if for every agent $a_i\in N$, truth-telling is a dominant strategy for any against any strategy profile of other agents given any type of agent $a_i$ (i.e., any preference of $a_i$). Due to the revelation principle, we only need to consider direct mechanims in which agents simply report their types (or preferences, in our setting). For more information, please see BLAH. (TODO).










\section{Main Technical Results} \label{GT:sec:Mechanism}

Let us present our first impossibility result which states that strategy-proofness and stability of an invitation are not compatible in \AOIP. 

%%%% ========== Impossibility Results
\begin{theorem} \label{GT:thm:impossibility}
No strategy-proof mechanism can find a stable invitation (even if it exists) given arbitrary instances of \AOIPs when the number of agents is at least two.
\end{theorem}
\begin{proof}
Example~\ref{GT:eg:multiple_stable} can serve as a proof; no strategy-proof mechanism can find a stable invitation for this instance.
\end{proof}

Intuitively, this can be explained by conflicting interests of the organizer and agents -- the organizer is trying to maximize attendance while the agents (with \DEC-preferences) to minimize. 
This intuition begs the question: What if all agents have \INC-preferences instead? When all agents have \INC-preferences, we obtain a positive result in this case as Theorem~\ref{GT:thm:mechanism} states. 

\begin{theorem} \label{GT:thm:mechanism}
	There is a strategy-proof mechanism for \INC-instances of \AOIP, which can also find a stable invitation in linear time (after sorting) and its size is maximum among all stable invitations.
\end{theorem}
\begin{proof}
For simplicity, let us assume that each agent reports her threshold value (i.e., $l_i$ as defined in Definition (to be added)) as $L_i$ ($L_i$ may differ from $l_i$). Our mechanism then chooses the largest $k$ such that $L_k \leq k$ holds and chooses the set of $k$ agents with largest threshold values (if no such $k$ exists, mechanism chooses the empty invitation). Algorithm~\ref{alg:mechanism} describes this mechanism.
\begin{algorithm}
	\caption{Strategy-proof Mechanism}
	\label{alg:mechanism}
\begin{algorithmic}[1]
	\State \textbf{Input:} $(N, \{L_i\})$ ~ // $\{L_i\}$ is sorted decreasingly
	\For{$k := n, n-1, n-2, \dots, 2, 1$}
		\If{$L_k \leq k$}
			\State \textbf{return} $S = \{a_1, a_2, \dots, a_{k-1}, a_{k}\}$
		\EndIf
	\EndFor
	\State \textbf{return} $S = \emptyset$
\end{algorithmic}
\end{algorithm} 
	
We first show that the invitation $S$ that is returned by the mechanism in line 4 is always stable (with respect to the reported threshold values, $\{L_i\}$). If the mechanism returns $S$ in line 4, we know that it contains precisely $k$ agents (i.e. $k = |S|$). Since we sorted the threshold values of agents, for each $a_i \in S$ we know that $L_i \leq L_k \leq k$, which implies that $S$ is individually rational. To see why $S$ is envy-free, for any agent $a_j\not\in S$ we know that $j > k$ (otherwise $a_j\in S$) and that $L_j \geq L_k$ (because we sorted threshold values). Furthermore, since the mechanism did not return an invitation in line 5 during the iteration when $k = j$ (recall that $k$ is iterating in decreasing order), this implies that $L_j > j$ for all $j > k$ (otherwise the mechanism would have returned a different invitation and terminated). Therefore for any $a_j\not\in S$, we conclude that $L_j > j > k$, which implies $L_j \geq k+2$. Therefore $a_j$ is envy-free of $S$ because $L_j > |S| + 1$ (i.e. even if $a_j$ joins $S$, it is still not preferred to her outside option). Therefore if the mechanism returns any invitation in line 5, then it is stable. Now suppose the mechanism does not return any invitation in line 5, but it eventually returns the empty invitation in line 9. Then $S = \emptyset$ must be stable; it is individually rational by definition. It is also envy-free because we know that $L_k > k$ for all $k \geq 1$, which implies that $L_k > 1$ for all $k$. Therefore an empty invitation is stable in this case.

	Next we show that the mechanism indeed returns a maximum stable invitation given truthful threshold values (if it exists). Let $S^*$ be a maximum stable invitation, and let us focus on the iteration when $k = |S^*|$. We claim that the mechanism will return a stable invitation of size $k$.  Since $S^*$ is a stable invitation, we know that for all $a_i\in S^*$, it holds that $L_i \leq |S^*| = k$. Therefore, when the threshold values are sorted, this implies that $L_j \leq k$ for all $j\leq k$; in particular, $L_k \leq k$. Therefore the mechanism executes lines 3-4, and returns an invitation $S$ of size $k$.  In the case where the maximum stable invitation is empty, the mechanism will clearly return an empty invitation (because we have shown that the mechanism only returns a stable invitation, it would not return any invitation in line 5 but eventually execute line 9). 

	Finally we show that the mechanism is strategy-proof. To show this, we will show that truth-telling is a weakly dominant strategy for any agent. 
	Let us consider some fixed agent $a_i$ and also fix the action profile of the remaining agents to be $L_{-i}$ (which may or may not be truthful).
	Let us assume that the mechanism sorts the threshold values $(L_i, L_{-i})$ as $L_1 \leq L_2 \leq \cdots \leq L_{i-1} \leq L_i \leq L_{i+1} \leq \cdots \leq L_n$ (since we argue for an arbitrary agent $a_i$, this assumption can be made without loss of generality).
	Let $S_L$ denote the invitation returned by the mechanism given $(l_i, L_{-i})$ and let $k_L = |S_L|$ (i.e. when $L_i = l_i$ and thus $a_i$ is truth-telling). 

	We first consider the case where $a_i$ over-reports.  That is, we consider an action profile $(v_i, L_{-i})$ where $v_i > l_i$. Given $(v_i, L_{-i})$, let $M_1 \leq M_2 \leq \cdots \leq M_{n}$ denote the sorted list of the threshold values (we use $M$ to distinguish from the case where $a_i$ reported truthfully). Let $S_M$ denote the invitation returned by the mechanism given $(v_i, L_{-i})$ and let $k_M = |S_M|$. Between the two action profiles $(l_i, L_{-i})$ and $(v_i, L_{-i})$, the only difference (in terms of the threshold values) is between $l_i$ and $v_i$. Since $v_i > l_i$, we know that $L_j \leq M_j$ for all $j$ and in particular that $L_{k_M} \leq M_{k_M}$. If we show that $k_M \leq k_L$, then it implies that $a_i$ has no incentive to over-report because $a_i$ has an \INC-preference (hence $a_i$ weakly prefers $S_L$ to $S_M$). Suppose $k_M > k_L$ instead. Since the mechanism returns an invitation of size $k_M$ given $(v_i, L_{-i})$, we know by our construction that $M_{k_M} \leq k_M$, which in turn implies $L_{k_M} \leq k_M$ (because $L_{k_M} \leq M_{k_M}$). However, since the mechanism returns an invitation of size $k_L$ given $(l_i, L_{-i})$, this implies that $L_j > j$ for all $j > k_L$ and in particular that $L_{k_M} > k_M$.  This is a contradiction, and we conclude that $k_M \leq k_L$ if agent $a_i$ over-reports with $v_i > l_i$. 

	Next we consider the case where $a_i$ under-reports. Similarly to the previous case, we consider an action profile $(v_i, L_{-i})$ where $v_i < l_i$. Given $(v_i, L_{-i})$, let $M_1 \leq M_2 \leq \cdots \leq M_{n}$ denote the sorted list of the threshold values (we use $M$ to distinguish from the case where $a_i$ reported truthfully). Let $S_M$ denote the invitation returned by the mechanism given $(v_i, L_{-i})$ and let $k_M = |S_M|$. Between the two action profiles $(l_i, L_{-i})$ and $(v_i, L_{-i})$, the only difference (in terms of the threshold values) is between $l_i$ and $v_i$. Since $v_i < l_i$, we know that $M_j \leq L_j$ for all $j \leq i$ and that $M_j = L_j$ for all $j > i$. 

	We consider two sub-cases of under-reporting and show that in both cases $a_i$ has no incentive to under-report.  The easier case is when $a_i \in S_L$. We show that in this case $|S_M| = k_M \leq k_L = |S_L|$. Suppose $k_M > k_L$ instead. Since $a_i \in S_L$, this implies that $k_L \geq i$ (because we assumed that $L_j < L_i = l_i$ for all $j < i$). Since the mechanism returns an invitation of size $k_M$ given $(v_i, L_{-i})$, we know by our construction that $M_{k_M} \leq k_M$. Yet we showed earlier that $M_j = L_j$ for all $j > i$, which in particular implies that $M_{k_M} = L_{k_M}$ because $k_M > k_L \geq i$. However the mechanism returns an invitation of size $k_L$ given $(l_i, L_{-i})$, which implies that $L_j > j$ for all $j > k_L$ (and in particular, $L_{k_M} > k_M$). This is a contradiction, and we conclude that $k_M \leq k_L$ if $a_i$ under-reports and $a_i\in S_L$. 

	Next we consider the other sub-case where $a_i$ under-reports and $a_i\not\in S_L$. We will show that $|S_M| = k_M < l_i$, which means that the invitation returned by the mechanism when $a_i$ under-reports is not preferred to her outside option of not attending, and therefore $a_i$ has no incentive to under-report. Suppose $k_M \geq l_i$ instead. Since $a_i \not\in S_L$, we know that $k_L < i$ and that $l_i > i$ (otherwise the mechanism would have returned an invitation of size $i$ or larger given $(l_i, L_{-i})$). Therefore $k_M \geq l_i$ implies that $k_M > i$. Since the mechanism returns $S_M$ given $(v_i, L_{-i})$, we know that $M_{k_M} \leq k_M$. However the mechanism given $(l_i, L_{-i})$ returns an invitation of size $k_L < i$, which implies that $L_{k_M} > k_M$. We earlier showed that $L_j = M_j$ for all $j > i$ if $a_i$ under-reports, and in particular we have that $L_{k_M} = M_{k_M}$. Since $L_{k_M} > k_M$ and $M_{k_M} \leq k_M$, this is a contradiction, and we conclude that if $a_i$ under-reports and $a_i\not\in S_L$ then $|S_M| = k_M < l_i$. 

	In all cases we have shown that truth-telling is a weakly dominant strategy for $a_i$ regardless of what the remaining agents report. Therefore the mechanism is strategy-proof.  Combined with our previous arguments, this shows that the mechanism is able to find a maximum stable invitation (provided that all agents play their weakly dominant strategy, truth-telling).
\end{proof} 	 %TODO: Also include anecdnote from Matt Jackson.



% Since no strategy-proof mechanisms can find a stable invitation,
% one can instead seek to design a strategy-proof mechanism that can find a non-empty IR invitation.
% We show that this is also impossible as the following theorem states.
%
% \begin{theorem} \label{GT:thm:impossibility_IR}
% 	No strategy-proof mechanism can find a non-empty individually rational (IR) invitation, even if it exists, for arbitrary instances of \AOIP.
% \end{theorem}
% \begin{proof}%TODO: This example requires that agents have ordinal preferences (agent 2 and 3). Can I find another example?
% Consider three agents with their approval sets shown as follows:
% \begin{equation*}
% 		S_1 = \{3\},~~ S_2 = \{2, 3\}, ~~ S_3 = \{2, 3\}.
% \end{equation*}
% There are two non-empty IR invitations: $I_1 = \{a_1, a_2, a_3\}$ and $I_2 = \{a_2, a_3\}$.
% If a mechanism chooses $I_1$ given $(S_1, S_2, S_3)$, then $a_2$ can report $\hat{S}_2 = \{2\}$ instead, which makes $I_2$ the only non-empty IR invitation given $(S_1, \hat{S}_2, S_3)$.
%  Similarly, if a mechanism chooses $I_2$ given $(S_1, S_2, S_3)$, then $a_3$ can report $\hat{S}_3=\{3\}$ instead to make $I_3$ the only non-empty IR invitation. The rest of the proof is similar to that of Theorem~\ref{GT:thm:impossibility}.
% \end{proof}
% Earlier we emphasized that the conflict between agent(s) and the organizer is the main factor that leads to an impossibility result.
% Indeed, in the example we used in the proof of Theorem~\ref{GT:thm:impossibility}, both agents have \DEC-preferences while the organizer's goal is to maximize attendance.




\subsection{Randomized Mechanisms} \label{GT:sec:randomized}
Although we have so far only discussed deterministic mechanisms, our impossibility results can be extended to randomized mechanisms. First we define $Z$ to be a mapping from $V$ to $\Pi(U)$ where $\Pi(U)$ denotes the set of all probability distributions over $U$. The definition of a strategy-proof mechanism must change accordingly -- we do this by adopting the axioms in the von Neumann-Morgenstern utility theorem~\cite{von1947theory}. We introduce lotteries over invitations and define preferences of agents over lotteries. Given a probability distribution over invitations, one can compute the expected cardinal utility of lotteries. We then define a strategy-proof mechanism analogously to Definition~\ref{GT:def:mechanism}: for each $a_i$, it must hold that the expected utility of $Z(P_i, v_{-i})$ is no less than the expected utility of $Z(v_i, v_{-i})$ for all $v_i\in V_i$ and for all $v_{-i} \in V_{-i}$. The impossibility result given by Theorem~\ref{GT:thm:impossibility} still holds: If $(V, Z)$ is a strategy-proof mechanism, then $Z(P_1, P_2)$ must assign zero probability to both $\{a_1\}$ and $\{a_2\}$, yet these are the only two stable invitations.  All other impossibility results we mention in this work can be extended in this manner.

We can extend our results in a different direction by considering multiple time-alternatives for the event. In such settings, agents may have preferences over time-alternatives for the event, in addition to size of invitations.   
In the non-strategic case, our easiness result is still applicable: One can run the algorithm used in Theorem~(to be added  GT:thm:asip:algo) iteratively for each time-alternative, and choose the maximum stable invitation among all.
In the strategic case, our impossibility results immediately imply the same negative results. 
For \INC-instances of \AOIP, we obtain a similar impossibility result even if there is only two time-alternatives. The intuition is that over-reporting ($L_i > l_i$) can give the veto power to an agent, which prevents us from designing a strategy-proof mechanism even for \INC-instances of \AOIP. Note that all of our impossibility results can be naturally extended to the Group Activity Selection Problem by Darmann et al.~\cite{GASP12WINE} since \AOIPs is a sub-class of \GASPs with a single activity.


\subsection{Extensions to Stable Invitations Problem}


\subsection{Extensions to Group Activity Selection Problem}


\section{Discussion}

While we focused on designing algorithms or proving computational hardness results in previous chapters, the focus of this chapter is on mechanism design and impossibility results (much like computational hardness results). In mechanism design theory, the objective is to design a mechanism which is given an action profile of all agents and chooses an outcome (which can be probabilistic) such that the mechanism satisfies certain properties. One of the most important properties is incentive compatibility -- agents must be incentivized to act in a certain way (such as truth-telling) because no agent can be better off by acting in a different way. In many settings, utilites of agents may be transferable (such as money), which provides ways to compensate for agents who end up with less desirable outcomes. However, in social settings like the ÃŸgroup scheduling and assignment problems, it is more reasonable to assume that utilites of agents are assumed to be non-transferable, and therefore it is not possible to compenstate agents for any outcome. 
